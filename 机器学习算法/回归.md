# 回归模型（Learning Algorithm ）
- 可解释性和灵活度比较好
- baseline
- 连续值：回归；离散：分类
- 线性回归：连续值。逻辑回归：离散。
### 线性回归
- 监督学习（监督，半监督，无监督，有无标准答案）
- trainning，预测
- 损失函数（loss/cost function）
  - 做的好与不好，怎么去衡量最好
  - 先给好一组权重，通过损失函数衡量权重好与不好。优化，让损失函数尽可能小
  - air to loss
  - 损失函数各种各样，不一定是差值的平方
  - 最小化损失函数
  - GD：梯度下降
  - SGD
  - 通过迭代的方式，变得损失函数越来越小
  - 曲线斜率变化最快的地方，梯度
  - 超参数
  - 梯度下降与学习率
    - 学习率太大，会震荡，有可能还会不收敛
    - 学习率太小，收敛太慢，效率比较低
  - 欠拟合（underfitting）和过拟合(overfitting)
    - 欠拟合：非要用直线拟合曲线的点
    - 过拟合：过于针对每一个点，不具备普遍性
- 线性回归与正则化
  - 正则化：
    - 控制参数幅度，不让模型“无法无天”
    - 限制参数搜索空间
### 逻辑（斯蒂）回归
- 解决分类问题。
  - 线性值 + 阈值
  - 健壮度不够，噪声一来，马上“投降”
  - 定义不好阈值
- 离散值 sigmoid
- 判定边界
- 线性回归 + sigmoid
-  
